---
format: pdf
---

## ![NagÅ‚Ã³wek](https://github.com/zuzanasilowska/pakiety/blob/main/w%20negocjacjach%20(4).png?raw=true)

**1. Wprowadzenie**

Niniejszy raport skupia siÄ™ na analizie mocy testÃ³w statystycznych w sytuacjach, gdy zaÅ‚oÅ¼enia dotyczÄ…ce danych sÄ… stopniowo osÅ‚abiane. Testy statystyczne stanowiÄ… kluczowy element weryfikacji hipotez i oceny, czy badane prÃ³bki speÅ‚niajÄ… okreÅ›lone warunki rozkÅ‚adu. W statystyce, jednym z gÅ‚Ã³wnych wyzwaÅ„ jest dobÃ³r odpowiednich testÃ³w, ktÃ³re nie tylko wykrywajÄ… odchylenia od normalnoÅ›ci, ale rÃ³wnieÅ¼ sÄ… odporne na rÃ³Å¼ne formy zaburzeÅ„ danych. Celem raportu jest wiÄ™c nie tylko zbadanie skutecznoÅ›ci testÃ³w w optymalnych warunkach, ale takÅ¼e analiza ich dziaÅ‚ania w sytuacjach, gdy zaÅ‚oÅ¼enia o normalnoÅ›ci rozkÅ‚adu danych nie sÄ… w peÅ‚ni speÅ‚nione.

W naszych badanich wykorzystaÅ‚yÅ›my trzy popularne testy normalnoÅ›ci:

-   Test Shapiro-Wilka: to test parametryczny, ktÃ³ry weryfikuje normalnoÅ›Ä‡ danych poprzez analizÄ™ stosunku wariancji prÃ³bki do wariancji oczekiwanej w przypadku normalnoÅ›ci,

-   Test KoÅ‚mogorowa-Lillieforsa: to test nieparametryczny, ktÃ³ry mierzy maksymalnÄ… rÃ³Å¼nicÄ™ miÄ™dzy dystrybuantÄ… empirycznÄ… a teoretycznÄ… funkcjÄ… rozkÅ‚adu normalnego,

-   Test Jarque-Bera: to test statystyczny oparty na skoÅ›noÅ›ci i kurtozie, ktÃ³ry ocenia odchylenia od normalnoÅ›ci na podstawie momentÃ³w wyÅ¼szych rzÄ™dÃ³w.

KaÅ¼dy z powyÅ¼ej wymienionych testÃ³w ma swoje zalety i ograniczenia, a ich skutecznoÅ›Ä‡ zaleÅ¼y od charakterystyki danych. Celem analizy jest porÃ³wnanie ich mocy w rÃ³Å¼nych warunkach.

**2. Zadania**

**Zadanie 1**

RozwaÅ¼my prÃ³bÄ™ $(X_1, ... X_{100})$ z rozkÅ‚adu normalnego $ğ’© (2,\ 1)$ przeksztaÅ‚conego przez transformatÄ™ Sinh-arcsinh z $\nu = 0$. KorzystajÄ…c z symulacji Monte Carlo wykonaj wykres funkcji mocy w zaleÅ¼noÅ›ci od $ğœ$ na przedziale $(0.5,\ 2)$ dla wszystkich trzech testÃ³w. Czy istnieje test jednostajnie najmocniejszy spoÅ›rÃ³d nich?

UMPT to test to test statystyczny, ktÃ³ry dla kaÅ¼dego poziomu istotnoÅ›ci $\alpha$ ma najwiÄ™kszÄ… moc spoÅ›rÃ³d wszystkich testÃ³w w danym problemie.

**Moc testÃ³w:** Moc testu statystycznego to prawdopodobieÅ„stwo odrzucenia hipotezy zerowej, gdy jest ona faÅ‚szywa.

```{r, echo = FALSE, message = FALSE, warning=FALSE, dev="cairo_pdf"}
#install.packages(c("gamlss.dist", "nortest", "moments"))

library(gamlss.dist)
library(nortest)
library(moments)

n <- 100 
mu <- 2
sigma <- 1
nu <- 0
taus <- seq(0.5, 2, by = 0.1)
n_sim <- 1000 

sinh_arcsinh <- function(x, tau, nu) {
  sinh(tau * (asinh(x) + nu))
}

power_results <- matrix(0, nrow = length(taus), ncol = 3) 

for (i in seq_along(taus)) {
  tau <- taus[i]
  rejections <- matrix(0, nrow = n_sim, ncol = 3)
  
  for (j in 1:n_sim) {
    sample <- rnorm(n, mean = mu, sd = sigma)
    transformed_sample <- sinh_arcsinh(sample, tau = tau, nu = nu)
    
    rejections[j, 1] <- ifelse(shapiro.test(transformed_sample)$p.value < 0.05, 1, 0)
    
    rejections[j, 2] <- ifelse(lillie.test(transformed_sample)$p.value < 0.05, 1, 0)
    
    rejections[j, 3] <- ifelse(jarque.test(transformed_sample)$p.value < 0.05, 1, 0)
  }
  
  power_results[i, ] <- colMeans(rejections)
}

plot(taus, power_results[, 1], type = "l", col = "red", lwd = 2,
     xlab = expression(tau), ylab = "Moc testu",
     main = "Funkcja mocy dla rÃ³Å¼nych testÃ³w")
lines(taus, power_results[, 2], col = "blue", lwd = 2)
lines(taus, power_results[, 3], col = "green", lwd = 2)
legend("bottomright", legend = c("S-W", "K-L", "J-B"),
       col = c("red", "blue", "green"), lwd = 2)

```


Wyniki przedstawione na powyÅ¼szym wykresie pokazujÄ…, jak moc testÃ³w zmienia siÄ™ w zaleÅ¼noÅ›ci od parematry $\tau$:

-   WartoÅ›ci $\tau$ **bliskie 1**: Moc testÃ³w jest najmniejsza, co oznacza, Å¼e trudniej im wykryÄ‡ odchylenia od normalnoÅ›ci,
-   WartoÅ›ci dalekie od 1: Moc testÃ³w wzrasta, co wskazuje, Å¼e testy lepiej indentyfikujÄ… niezgodnoÅ›Ä‡ z rozkÅ‚adem normalnym.

**Dyskusja na temat mocy testÃ³w:**

-   Test Shapiro-Wilka wykazuje najwiÄ™kszÄ… moc w caÅ‚ym zakresie $\tau$, zwÅ‚aszcza dla skrajnych wartoÅ›ci (wykresy rÃ³Å¼niÄ… siÄ™ minimalnie w zaleÅ¼noÅ›ci od symulacji),
-   Test KoÅ‚mogorowa-Lillieforsa ma niÅ¼szÄ… moc niÅ¼ Shapiro-Wilk i Jarque-Bera, szczegÃ³lnie dla mniejszych odchyleÅ„. Jest mniej efektywny w wykrywaniu subtelnych rÃ³Å¼nic,
-   Test Jarque-Bera osiÄ…ga wartoÅ›ci mocy podobne do Shapiro-Wilka, ale jest mniej czuÅ‚y na niektÃ³re odchylenia.

**PorÃ³wnanie oraz wnioski**

-   **Shapiro-Wilk** ma najwyÅ¼szÄ… moc w caÅ‚ym zakresie $\tau$, co oznacza, Å¼e jest najlepszy w wykrywaniu nienormalnoÅ›ci, zwÅ‚aszcza w maÅ‚ych prÃ³bach,
-   **KoÅ‚mogorov-Lillefor** ma najniÅ¼szÄ… moc, co sugeruje, Å¼e nie jest najlepszym wyborem w tym wypadku,
-   PatrzÄ…c na wykres, test Shapiro-Wilka jest najczÄ™Å›ciej najmocniejszy, ale w niektÃ³rych zakresach $\tau$ test Jarque-Bera moÅ¼e osiÄ…gaÄ‡ podobne wartoÅ›ci. MoÅ¼emy jednak stwierdziÄ‡, Å¼e test **Shapiro-Wilka** jest jednoznacznie najmocniejszy.

#### Zadanie 2

Mamy prÃ³bÄ™ $(X_1, ... X_{100})$ z rozkÅ‚adu normalnego $ğ’© (2, 1)$ przeksztaÅ‚conego przez transformatÄ™ Sinh-arcsinh z $ğœ = 1$. KorzystajÄ…c z symulacji Monte Carlo wykonaj wykres funkcji mocy w zaleÅ¼noÅ›ci od $ğœˆ$ na przedziale $(âˆ’2, 2)$ dla wszystkich trzech testÃ³w. Czy istnieje test jednostajnie najmocniejszy spoÅ›rÃ³d nich?

```{r, echo = FALSE, message = FALSE, warning=FALSE}

tau <- 1
nus <- seq(-2, 2, by = 0.1)
power_results <- matrix(0, nrow = length(nus), ncol = 3)

for (i in seq_along(nus)) {
  nu <- nus[i]
  rejections <- matrix(0, nrow = n_sim, ncol = 3)
  
  for (j in 1:n_sim) {
    sample <- rnorm(n, mean = mu, sd = sigma)
    transformed_sample <- sinh_arcsinh(sample, tau = tau, nu = nu)
    
    rejections[j, 1] <- ifelse(shapiro.test(transformed_sample)$p.value < 0.05, 1, 0)
    
    rejections[j, 2] <- ifelse(lillie.test(transformed_sample)$p.value < 0.05, 1, 0)
    
    rejections[j, 3] <- ifelse(jarque.test(transformed_sample)$p.value < 0.05, 1, 0)
  }
  
  power_results[i, ] <- colMeans(rejections)
}

```

Parametr $v$ zmienia siÄ™ w przedziale (-2,2), co osÅ‚abia zaÅ‚oÅ¼enia normalnoÅ›ci, transformacja Sinh-arcsinh zmienia ksztaÅ‚t rozkÅ‚adu, co powoduje, Å¼e dane nie sÄ… juÅ¼ dokÅ‚adnie normalne.

```{r, echo = FALSE, message = FALSE, warning=FALSE, dev="cairo_pdf"}
plot(nus, power_results[, 1], type = "l", col = "red", lwd = 2,
     xlab = expression(nu), ylab = "Moc testu",
     main = "Funkcja mocy dla rÃ³Å¼nych testÃ³w")
lines(nus, power_results[, 2], col = "blue", lwd = 2)
lines(nus, power_results[, 3], col = "green", lwd = 2)
legend("topright", legend = c("Shapiro-Wilk", "Kolmogorov-Lilliefors", "Jarque-Bera"),
       col = c("red", "blue", "green"), lwd = 2)
```

Z wykresu moÅ¼na zauwaÅ¼yÄ‡ kilka istotnych rzeczy:

-   **Dla wartoÅ›ci** $v$ bliskich 0 (czyli gdy dane sÄ… bliskie normalnoÅ›ci), moc testÃ³w jest bardzo niska: Oznacza to, Å¼e testy nie wykrywajÄ… odchyleÅ„ od normalnoÅ›ci, co jest spodziewane, bo dane sÄ… wtedy w przybliÅ¼eniu normalne,
-   **Dla duÅ¼ych wartoÅ›ci** $|v|$, szczegÃ³lnie ujemnych $v$, most testu wzrasta: oznacza to, Å¼e im wiÄ™ksza deformacja rozkÅ‚adu, tym Å‚atwiej testom wykryÄ‡, Å¼e dane nie pochodzÄ… z rozkÅ‚adu normalnego. Dla $v > 0$ rozkÅ‚ad bardziej przypomina rozkÅ‚ad normalny, wiÄ™c testy czÄ™Å›ciej mylnie nie odrzucajÄ… hipotezy zerowej.

**PorÃ³wnanie testÃ³w i wnioski:**

-   Shapiro-Wilk jest najbardziej czuÅ‚y na odchylenia: dla duÅ¼ych wartoÅ›ci $v$ jego moc roÅ›nie najszybciej,
-   Jarque-Bera ma podobnÄ… moc do Shapiro-Wilka, ale jest nieco mniej efektywny w wykrywaniu nieznacznych odchyleÅ„,
-   KoÅ‚mogorov-Lillefors ma najniÅ¼szÄ… moc w caÅ‚ym zakresie $v$, co oznacza, Å¼e jest najmniej efektywny w wykrywaniu odchyleÅ„ od normalnoÅ›ci,
-   Podobnie jak w zadaniu 1, **test Shapiro-Wilka wykazuje najwyÅ¼szÄ… moc w wiÄ™kszoÅ›ci przypadkÃ³w**, co sugeruje, Å¼e jest najlepszym wyborem. Jednak dalej w niektÃ³rych zakresach, test Jarque-Bera ma zbliÅ¼onÄ… skutecznoÅ›Ä‡. Nie moÅ¼na jednoznacznie stwierdziÄ‡, Å¼e istnieje test jednostajnie najmocniejszy.

Wyniki tego zadania pokazujÄ…, Å¼e gdy zaÅ‚oÅ¼enia normalnoÅ›ci sÄ… osÅ‚abione (tj. dane sÄ… przeksztaÅ‚cone przez transformacjÄ™ Sinh-arcsinh z rÃ³Å¼nymi wartoÅ›ciami $v$), moc testÃ³w znaczÄ…co siÄ™ zmienia. W szczegÃ³lnoÅ›ci dla wartoÅ›ci $v \approx 0$, czyli gdy dane sÄ… bliskie normalnoÅ›ci, moc testÃ³w jest bardzo niska. To oznacza, Å¼e w tym zakresie testy nie sÄ… w stanie odrÃ³Å¼niÄ‡ lekko zmodyfikowanego rozkÅ‚adu od normalnego. JeÅ›li dane tylko lekko odbiegajÄ… od normalnoÅ›ci, testy mogÄ… nie wykryÄ‡ tego odchylenia i bÅ‚Ä™dnie zaakceptowaÄ‡ hipoteze zerowÄ…. JeÅ›li zaÅ‚oÅ¼enia normalnoÅ›ci sÄ… mocniej naruszone (duÅ¼e wartoÅ›ci $|v|$), testy zaczynajÄ… dziaÅ‚aÄ‡ lepiej.

#### Zadanie 3

Mamy prÃ³bÄ™ $(X_1, ... X_{100})$ takÄ…, Å¼e zmienne losowe $ğ‘Œ_ğ‘– = \frac{ğ‘‹_ğ‘–âˆ’2}{1}$ sÄ… z rozkÅ‚adu t-Studenta $ğ’¯ (ğœˆ)$. KorzystajÄ…c z symulacji Monte Carlo wykonaj wykres funkcji mocy w zaleÅ¼noÅ›ci od $v$ na przedziale $(0.05, 20)$ dla wszystkich trzech testÃ³w. Czy istnieje test jednostajnie najmocniejszy spoÅ›rÃ³d nich?

W niniejszym zadaniu dokonaliÅ›my transformacji, co sprawia, Å¼e zmienne $Y_i$ majÄ… rozkÅ‚ad t-tudenta. Parametr $v$ kontroluje liczbÄ™ stopni swobody, co bezpoÅ›rednio wpÅ‚ywa na ksztaÅ‚t rozkÅ‚adu. Dla duÅ¼ych $v$ rozkÅ‚ad $T(v)$ staje siÄ™ coraz bardziej zbliÅ¼ony do rozkÅ‚adu normalnego. **Na podstawie wykresu moÅ¼emy stwierdziÄ‡, Å¼e:**

-   Dla maÅ‚ych wartoÅ›ci $v$ moc testÃ³w jest wysoka,
-   Gdy $v$ jest maÅ‚e, rozkÅ‚ad t-Studenta znacznie roÅ¼ni siÄ™ od normalnego (ma ciÄ™Å¼sze ogony). Wszystkie testy dobrze wykrywajÄ… to odchylenie i czÄ™sto odrzucajÄ… hipoteze zerowÄ…,
-   NajwiÄ™kszÄ… moc w tej strefie (maÅ‚e $v$) ma Shapiro-Wilk i Jarque-Bera, natomiast KoÅ‚mogorov-Lillefors jest najsÅ‚abszy,
-   Dla duÅ¼ych wartoÅ›ci $v$ moc testÃ³w drastycznie spada. Gdy $v$ roÅ›nie, rozkÅ‚ad t-Studenta coraz bardziej przypomina normalny, wiÄ™c testy majÄ… trudnoÅ›Ä‡ z odrzuceniem hipotezy zerowej.

```{r, echo = FALSE, message = FALSE, warning=FALSE}
library(tseries)

n <- 100
mc <- 1000
alpha <- 0.05
nus <- seq(0.05, 20, by = 0.05)

power_results <- matrix(0, nrow = length(nus), ncol = 3)
colnames(power_results) <- c("Shapiro-Wilk", "Kolmogorov-Lilliefors", "Jarque-Bera")

for (i in seq_along(nus)) {
  nu <- nus[i]
  rejections <- matrix(0, nrow = mc, ncol = 3)
  
  for (j in 1:mc) {
    Y <- rt(n, df = nu)
    
    rejections[j, 1] <- ifelse(shapiro.test(Y)$p.value < alpha, 1, 0)
    
    rejections[j, 2] <- ifelse(lillie.test(Y)$p.value < alpha, 1, 0)
    
    rejections[j, 3] <- ifelse(jarque.bera.test(Y)$p.value < alpha, 1, 0)
  }
  
  power_results[i, ] <- colMeans(rejections)
}


```

```{r, echo = FALSE, message = FALSE, warning=FALSE, dev="cairo_pdf"}
plot(nus, power_results[, 1], type = "l", col = "red", lwd = 2,
     xlab = expression(nu), ylab = "Moc testu",
     main = "Funkcja mocy dla rÃ³Å¼nych testÃ³w")
lines(nus, power_results[, 2], col = "blue", lwd = 2)
lines(nus, power_results[, 3], col = "green", lwd = 2)
legend("topright", legend = c("Shapiro-Wilk", "Kolmogorov-Lilliefors", "Jarque-Bera"),
       col = c("red", "blue", "green"), lwd = 2)

```


**PorÃ³wnanie:**

-   **Jarque-Bera**: Najlepszy w wykrywaniu odchyleÅ„ od normalnoÅ›ci. Dobrze wykrywa odchylenia w skoÅ›noÅ›ci i kurtozie, ktÃ³re sÄ… kluczowe dla rozkÅ‚adu t-Studenta,
-   **Shapiro-Wilk**: Jest skuteczny dla maÅ‚ych wartoÅ›ci $v$, ale traci moc szybciej niÅ¼ Jarque-Bera. DziaÅ‚a gorzej, poniewaÅ¼ jest wraÅ¼liwy na rÃ³Å¼nice w ksztaÅ‚cie rozkÅ‚adu,
-   **KoÅ‚mogorov-Lilleforsa**: Wypada najgorzej, ma najniÅ¼szÄ… moc prawie w caÅ‚ym zakresie.
-   **Test Jarque-Bera** jest jednostajnie najmocniejszym testem.

***Im bardziej osÅ‚abione sÄ… zaÅ‚oÅ¼enia, tym trudniej testom poprawnie wykryÄ‡ brak normalnoÅ›ci.***

**3. ZakoÅ„czenie**

Po przetestowaniu testÃ³w w rÃ³Å¼nych sytuacjach, gdy zaÅ‚oÅ¼enia dotyczÄ…ce rozkÅ‚adu danych byÅ‚y stopniowo osÅ‚abiane moÅ¼emy wysunÄ…Ä‡ nastÄ™pujÄ…ce wnioski:

- **Test Shapiro-Wilka** w wiÄ™kszoÅ›ci przypadkÃ³w ma najwiÄ™kszÄ… moc i jest najbardziej efektywny w wykrywaniu odchyleÅ„ od normalnoÅ›ci, choÄ‡ nie w kaÅ¼dym przypadku okazaÅ‚ siÄ™ najlepszy.

- **Test KoÅ‚mogorowa-Lillieforsa** wykazuje najniÅ¼szÄ… moc w prawie kaÅ¼dym przypadku i jest najmniej efektywny w wykrywaniu rÃ³Å¼nic w ksztaÅ‚cie rozkÅ‚adu.

- **Test Jarque-Bera** osiÄ…ga porÃ³wnywalne wyniki do testu Shapiro-Wilka, czasem lepiej wykrywajÄ…c nienormalnoÅ›Ä‡ rozkÅ‚adu (ostatnie zadanie).

- Transormacja danych pokazaÅ‚a, Å¼e testy najlepiej radzÄ… sobie, gdy rozkÅ‚ad danych istotnie rÃ³Å¼ni siÄ™ od rozkÅ‚adu normalnego i wyraÅºnie spada, gry rozkÅ‚ad jest mocno zbliÅ¼ony do normalnego.

- Widzimy, Å¼e najlepsze sÄ… testy Shapiro-Wilka oraz Jarque-Bera, osiÄ…gajÄ… najlepsze wyniki i w dwÃ³ch rÃ³Å¼nych przypadkach okreÅ›liliÅ›my kaÅ¼dy z nich jako jednoznacznie najmocniejszy, jednak Å¼aden z nich nie byÅ‚ najmocniejszy we wszystkich przypadkach. Test KoÅ‚mogorowa-Lillieforsa w kaÅ¼dym przypadku okazaÅ‚ siÄ™ najmniej efektywny.

